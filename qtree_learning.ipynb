{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = [-1.0, -5.0]\n",
    "high = [1.0, 5.0]\n",
    "# Test with some sample values\n",
    "samples = [(-1.2 , -5.1 ),\n",
    "           (-0.75,  3.25),\n",
    "           (-0.5 ,  0.0 ),\n",
    "           ( 0.25, -1.9 ),\n",
    "           ( 0.15, -1.75),\n",
    "           ( 0.75,  2.5 ),\n",
    "           ( 0.7 , -3.7 ),\n",
    "           ( 1.0 ,  5.0 )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtree import DNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GET]    Q((0.25, -1.9), 0) = (0.0, 24)\n",
      "[UPDATE] Q((0.15, -1.75), 0) = 1.0\n",
      "[GET]    Q((0.25, -1.9), 0) = (0.1, 24)\n"
     ]
    }
   ],
   "source": [
    "class QTree:\n",
    "    \"\"\"Composite Q-table with an internal tile coding scheme.\"\"\"\n",
    "    \n",
    "    def __init__(self, lower, upper, split, action_size):\n",
    "        \"\"\"Create regular tile, implemented with tree structure\n",
    "        Parameters\n",
    "        ----------\n",
    "        lower: array-like\n",
    "            Lower bounds of grid for each dimension\n",
    "        upper: array-like\n",
    "            Upper bounds of grid for each dimension\n",
    "        split: int\n",
    "            number of cells for each dimension\n",
    "            TODO: same value for every dimension\n",
    "        action_size: int\n",
    "            number of admissible actions\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.state_sizes = len(lower)\n",
    "        self.qtree = self.regular_qtree(lower, upper, split, action_size)\n",
    "\n",
    "    def regular_qtree(self, lower, upper, split, action_size):\n",
    "        MAXHEIGHT = int(np.log2(split) - 1)\n",
    "        ACTIONSIZE = action_size\n",
    "\n",
    "        init_lower = np.array(lower)\n",
    "        init_upper = np.array(upper)\n",
    "        init_dim = 0\n",
    "        init_middle = (init_lower + init_upper) / 2\n",
    "        init_idx = 0\n",
    "        init_height = 0\n",
    "\n",
    "        DIM = len(lower)\n",
    "        assert len(lower) == len(upper) # state vector dimension should match\n",
    "\n",
    "        root = DNode(init_middle[init_dim], init_dim)\n",
    "\n",
    "        def reggrid_nd_q(idx, lower, upper, cur_height, n_dim):\n",
    "            middle = (lower + upper)/2\n",
    "\n",
    "            if cur_height > MAXHEIGHT:\n",
    "                if n_dim == DIM - 1:\n",
    "                    root[idx] = DNode(idx)\n",
    "                    root[idx].q = np.zeros(ACTIONSIZE)\n",
    "                    return\n",
    "                else:\n",
    "                    cur_height = 0\n",
    "                    n_dim += 1\n",
    "                    lower = init_lower\n",
    "                    upper = init_upper\n",
    "                    middle = (lower + upper) / 2\n",
    "                    root[idx] = DNode(middle[n_dim], n_dim)\n",
    "\n",
    "            if idx > 0:\n",
    "                root[idx] = DNode(middle[n_dim], n_dim)\n",
    "\n",
    "            reggrid_nd_q(2*idx+1, lower, middle, cur_height + 1, n_dim)\n",
    "            reggrid_nd_q(2*idx+2, middle, upper, cur_height + 1, n_dim)\n",
    "\n",
    "        reggrid_nd_q(init_idx, init_lower, init_upper, init_height, init_dim)\n",
    "        return root\n",
    "\n",
    "    def search_spacial(self, root, test_array): \n",
    "        \"\"\"binary search on decision tree\"\"\"\n",
    "        # Base Cases: root is null or key is present at root \n",
    "        if root is None or root.dim is None: \n",
    "            # returns q-value array, and its index of the node in the tree\n",
    "            return root.q, root.value\n",
    "\n",
    "        # Key is greater than root's key \n",
    "        if test_array[root.dim] < root.value: \n",
    "            return self.search_spacial(root.left, test_array)\n",
    "        else:\n",
    "            # Key is smaller than root's key \n",
    "            return self.search_spacial(root.right, test_array)\n",
    "        \n",
    "    def get(self, state, action, return_index=True):\n",
    "        \"\"\"Get Q-value for given <state, action> pair.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        state: array_like\n",
    "            array representing the state in the original continuous space\n",
    "        action: int\n",
    "            Index or label of action\n",
    "        return_index: bool\n",
    "            returns index of the node if true\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        value: float\n",
    "            Q-value of given <state, action> pair\n",
    "        idx: int\n",
    "            index of the node in which the <state, action> pair falls\n",
    "        \"\"\"\n",
    "    \n",
    "        # TODO: parse state tree to get q-value array\n",
    "        qarray, idx = self.search_spacial(self.qtree, state)\n",
    "        # TODO: get q-value by accessing array\n",
    "        q_value = qarray[action]\n",
    "        if return_index:\n",
    "            return q_value, idx\n",
    "        else:\n",
    "            return q_value\n",
    "    \n",
    "    \n",
    "    def update(self, state, action, value, alpha=0.1):\n",
    "        \"\"\"Soft-update Q-value for given <state, action> pair to value.\n",
    "        \n",
    "        Instead of overwriting Q(state, action) with value, perform soft-update:\n",
    "            Q(state, action) = alpha * value + (1.0 - alpha) * Q(state, action)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        state : array_like\n",
    "            Vector representing the state in the original continuous space.\n",
    "        action : int\n",
    "            Index of desired action.\n",
    "        value : float\n",
    "            Desired Q-value for <state, action> pair.\n",
    "        alpha : float\n",
    "            Update factor to perform soft-update, in [0.0, 1.0] range.\n",
    "        \"\"\"\n",
    "        # get current value and its reference\n",
    "        q_value_current, idx = self.get(state, action)\n",
    "        # update the value based on observed value\n",
    "        self.qtree[idx].q[action] = alpha * value + (1.0 - alpha) * q_value_current\n",
    "\n",
    "# Test with a sample Q-table\n",
    "tq = QTree(low, high, 4, 2)\n",
    "s1 = 3; s2 = 4; a = 0; q = 1.0\n",
    "print(\"[GET]    Q({}, {}) = {}\".format(samples[s1], a, tq.get(samples[s1], a)))  # check value at sample = s1, action = a\n",
    "print(\"[UPDATE] Q({}, {}) = {}\".format(samples[s2], a, q)); tq.update(samples[s2], a, q)  # update value for sample with some common tile(s)\n",
    "print(\"[GET]    Q({}, {}) = {}\".format(samples[s1], a, tq.get(samples[s1], a)))  # check value again, should be slightly updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GET]    Q((0.15, -1.75), 0) = (0.1, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"[GET]    Q({}, {}) = {}\".format(samples[s2], a, tq.get(samples[s2], a)))  # check value again, should be slightly updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    \"\"\"Q-Learning agent that can act on a continuous state space by discretizing it.\"\"\"\n",
    "\n",
    "    def __init__(self, env, tq, alpha=0.02, gamma=0.99,\n",
    "                 epsilon=1.0, epsilon_decay_rate=0.9995, min_epsilon=.01, seed=0):\n",
    "        \"\"\"Initialize variables, create grid for discretization.\"\"\"\n",
    "        # Environment info\n",
    "        self.env = env\n",
    "        self.tq = tq \n",
    "        self.state_sizes = tq.state_sizes           # list of state sizes for each tiling\n",
    "        self.action_size = self.env.action_space.n  # 1-dimensional discrete action space\n",
    "        self.seed = np.random.seed(seed)\n",
    "        print(\"Environment:\", self.env)\n",
    "        print(\"State space sizes:\", self.state_sizes)\n",
    "        print(\"Action space size:\", self.action_size)\n",
    "        \n",
    "        # Learning parameters\n",
    "        self.alpha = alpha  # learning rate\n",
    "        self.gamma = gamma  # discount factor\n",
    "        self.epsilon = self.initial_epsilon = epsilon  # initial exploration rate\n",
    "        self.epsilon_decay_rate = epsilon_decay_rate   # how quickly should we decrease epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "\n",
    "    def reset_episode(self, state):\n",
    "        \"\"\"Reset variables for a new episode.\"\"\"\n",
    "        # Gradually decrease exploration rate\n",
    "        self.epsilon *= self.epsilon_decay_rate\n",
    "        self.epsilon = max(self.epsilon, self.min_epsilon)\n",
    "        \n",
    "        self.last_state = state\n",
    "        Q_s = [self.tq.get(state, action, return_index=False) for action in range(self.action_size)]\n",
    "        self.last_action = np.argmax(Q_s)\n",
    "        return self.last_action\n",
    "    \n",
    "    def reset_exploration(self, epsilon=None):\n",
    "        \"\"\"Reset exploration rate used when training.\"\"\"\n",
    "        self.epsilon = epsilon if epsilon is not None else self.initial_epsilon\n",
    "\n",
    "    def act(self, state, reward=None, done=None, mode='train'):\n",
    "        \"\"\"Pick next action and update internal Q table (when mode != 'test').\"\"\"\n",
    "        Q_s = [self.tq.get(state, action, return_index=False) for action in range(self.action_size)]\n",
    "        # Pick the best action from Q table\n",
    "        greedy_action = np.argmax(Q_s)\n",
    "        if mode == 'test':\n",
    "            # Test mode: Simply produce an action\n",
    "            action = greedy_action\n",
    "        else:\n",
    "            # Train mode (default): Update Q table, pick next action\n",
    "            # Note: We update the Q table entry for the *last* (state, action) pair with current state, reward\n",
    "            value = reward + self.gamma * max(Q_s)\n",
    "            self.tq.update(self.last_state, self.last_action, value, self.alpha)\n",
    "            \n",
    "#            self.tq.update_subtile_weight(self.last_state, self.last_action, value, self.slpha)\n",
    "#            self.tq.split_tile()\n",
    "            \n",
    "            # Exploration vs. exploitation\n",
    "            do_exploration = np.random.uniform(0, 1) < self.epsilon\n",
    "            if do_exploration:\n",
    "                # Pick a random action\n",
    "                action = np.random.randint(0, self.action_size)\n",
    "            else:\n",
    "                # Pick the greedy action\n",
    "                action = greedy_action\n",
    "\n",
    "        # Roll over current state, action for next step\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        return action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space: Box(6,)\n",
      "- low: [ -1.        -1.        -1.        -1.       -12.566371 -28.274334]\n",
      "- high: [ 1.        1.        1.        1.       12.566371 28.274334]\n",
      "Action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Create an environment\n",
    "env = gym.make('Acrobot-v1')\n",
    "env.seed(505);\n",
    "\n",
    "# Explore state (observation) space\n",
    "print(\"State space:\", env.observation_space)\n",
    "print(\"- low:\", env.observation_space.low)\n",
    "print(\"- high:\", env.observation_space.high)\n",
    "\n",
    "# Explore action space\n",
    "print(\"Action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: <TimeLimit<AcrobotEnv<Acrobot-v1>>>\n",
      "State space sizes: 6\n",
      "Action space size: 3\n"
     ]
    }
   ],
   "source": [
    "n_bins = 2\n",
    "#bins = tuple([n_bins]*env.observation_space.shape[0])\n",
    "#tiling_specs = [(bins, tuple([0.0]*env.observation_space.shape[0]))\n",
    "#               ]\n",
    "\n",
    "# tq = TiledQTable(env.observation_space.low, \n",
    "#                  env.observation_space.high, \n",
    "#                  tiling_specs, \n",
    "#                  env.action_space.n)\n",
    "tq = QTree(env.observation_space.low, env.observation_space.high, n_bins, env.action_space.n)\n",
    "agent = QLearningAgent(env, tq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000/10000 | Max Average Score: -103.3CPU times: user 6min 33s, sys: 7.72 s, total: 6min 41s\n",
      "Wall time: 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def run(agent, env, num_episodes=10000, mode='train'):\n",
    "    \"\"\"Run agent in given reinforcement learning environment and return scores.\"\"\"\n",
    "    scores = []\n",
    "    max_avg_score = -np.inf\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        # Initialize episode\n",
    "        state = env.reset()\n",
    "        action = agent.reset_episode(state)\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Roll out steps until done\n",
    "        while not done:\n",
    "            state, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            action = agent.act(state, reward, done, mode)\n",
    "\n",
    "        # Save final score\n",
    "        scores.append(total_reward)\n",
    "\n",
    "        # Print episode stats\n",
    "        if mode == 'train':\n",
    "            if len(scores) > 100:\n",
    "                avg_score = np.mean(scores[-100:])\n",
    "                if avg_score > max_avg_score:\n",
    "                    max_avg_score = avg_score\n",
    "            if i_episode % 100 == 0:\n",
    "                print(\"\\rEpisode {}/{} | Max Average Score: {}\".format(i_episode, num_episodes, max_avg_score), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "    return scores\n",
    "\n",
    "scores = run(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6befcb31d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(scores)), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
